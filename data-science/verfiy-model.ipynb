{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/Users/kiyas/Documents/Programming_Practice/nlp-project/data-engineering/data/multi-label-news.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.1 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the saved models\n",
    "model = joblib.load('data/trained_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\n",
    "A federal judge, citing a risk of “irreparable harm,” has temporarily restricted Elon Musk’s government efficiency team from accessing a critical Treasury Department payment system.\n",
    "\n",
    "The judge’s order, issued Saturday, temporarily halts access to a sensitive payment system that distributes Americans’ tax returns, Social Security benefits, disability payments and federal employees’ salaries.\n",
    "\n",
    "US District Judge Paul Engelmayer ordered the destruction of any downloaded information from the payment system by anyone given access to it since January 20, citing “the risk that the new policy presents of the disclosure of sensitive and confidential information and the heightened risk that the systems in question will be more vulnerable than before to hacking.”\n",
    "\n",
    "A hearing on the matter was set for February 14.\n",
    "\n",
    "Engelmayer’s order came in response to a suit filed by New York Attorney General Letitia James and 18 other state attorneys general against the Trump administration.\n",
    "\n",
    "The suit alleges the team led by Musk and staffed by young associates categorized as “special government employees” have been unlawfully granted access to the Treasury system that previously was restricted to specific government employees.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    '''Preprocess text by making it lowercase, removing text in square brackets,\n",
    "removing links, removing punctuation, and removing words containing numbers.'''\n",
    "    return re.sub('\\[.*?\\]|\\w*\\d\\w*|https?://\\S+|www\\.\\S+|<.*?>+|[%s]' %\n",
    "re.escape(string.punctuation), '', str(text).lower())\n",
    "\n",
    "def apply_stemming(sentence):\n",
    "    stemmer = nltk.SnowballStemmer(\"english\")\n",
    "    return ' '.join(stemmer.stem(word) for word in sentence.split(' '))\n",
    "\n",
    "def preprocess_and_clean(sentence):\n",
    "    '''Preprocess and clean the text'''\n",
    "    cleaned_text = preprocess_text(sentence)\n",
    "    stop_words = stopwords.words('english')\n",
    "    removed_stopwords_text = ' '.join(word for word in\n",
    "cleaned_text.split(' ') if word not in stop_words)\n",
    "    stemmed_text = ' '.join(apply_stemming(word) for word\n",
    "in removed_stopwords_text.split(' '))\n",
    "    return stemmed_text\n",
    "\n",
    "\n",
    "vectorizer = joblib.load('data/vectorizer.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: politics, Probability: 0.9543413842138971\n",
      "Category: crime, law and justice, Probability: 0.0273375297423233\n",
      "Category: society, Probability: 0.01259416880481507\n"
     ]
    }
   ],
   "source": [
    "processed_txt = preprocess_and_clean(txt)\n",
    "x = pd.DataFrame([processed_txt], columns = ['preprocessed_text'])\n",
    "X_train = vectorizer.transform(x['preprocessed_text'])\n",
    "\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_train)\n",
    "top3_indices = np.argsort(y_pred_proba[0])[::-1][:3]\n",
    "top3_categories = model.classes_[top3_indices]\n",
    "top3_probabilities = y_pred_proba[0][top3_indices]\n",
    "\n",
    "\n",
    "for category, probability in zip(top3_categories, top3_probabilities):\n",
    "    print(f\"Category: {category}, Probability: {probability}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
